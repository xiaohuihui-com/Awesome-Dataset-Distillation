# Awesome-Dataset-Distillation

## Paper&Code

| Year | Paper                                                        | Journal |                             Code                             |
| :--: | :----------------------------------------------------------- | :-----: | :----------------------------------------------------------: |
| 2022 | [Dataset Distillation by Matching Training Trajectories](https://arxiv.org/abs/2203.11932) |  CVPR   | [code](https://github.com/GeorgeCazenavette/mtt-distillation) |
| 2022 | [CAFE: Learning to Condense Dataset by Aligning Features](https://arxiv.org/abs/2203.01531) |  CVPR   |                              -                               |
| 2022 | [Dataset Condensation via Efficient Synthetic-Data Parameterization](https://arxiv.org/abs/2205.14959) |  ICML   | [code](https://github.com/snu-mllab/Efficient-Dataset-Condensation) |
| 2022 | [Dataset Condensation with Contrastive Signals](https://arxiv.org/abs/2202.02916) |  ICML   |         [code](https://github.com/Saehyung-Lee/DCC)          |
| 2022 | [Synthesizing Informative Training Samples with GAN](https://arxiv.org/abs/2204.07513) |    -    |                              -                               |
| 2022 | [Dataset Distillation using Neural Feature Regression](https://arxiv.org/abs/2206.00719) |    -    |                              -                               |
| 2022 | [DC-BENCH: Dataset Condensation Benchmark](https://arxiv.org/abs/2207.09639) |    -    |                              -                               |
| 2021 | [Dataset Condensation with Differentiable Siamese Augmentation](https://proceedings.mlr.press/v139/zhao21a.html), |  ICML   |   [code](https://github.com/VICO-UoE/DatasetCondensation)    |
| 2021 | [Dataset Distillation with Infinitely Wide Convolutional Networks](https://openreview.net/forum?id=hXWPpJedrVP) | NeurIPS |                              -                               |
| 2021 | [Dataset Meta-learning from Kernel Ridge-regression](https://arxiv.org/abs/2011.00050v3) |  ICLR   |                              -                               |
| 2021 | [Dataset Meta-Learning from Kernel Ridge-Regression](https://openreview.net/forum?id=l-PrrQrK0QR) |  ICLR   |                              -                               |
| 2021 | [Dataset Condensation with Distribution Matching](https://arxiv.org/abs/2110.04181) |  ICLR   |   [code](https://github.com/VICO-UoE/DatasetCondensation)    |
| 2021 | [Dataset Condensation with Gradient Matching](https://arxiv.org/abs/2006.05929) |  ICLR   |   [code](https://github.com/VICO-UoE/DatasetCondensation)    |
| 2021 | [Soft-Label Dataset Distillation and Text Dataset Distillation](https://ieeexplore.ieee.org/abstract/document/9533769) |  IJCNN  |                              -                               |
| 2020 | [Flexible dataset distillation: Learn labels instead of images](https://arxiv.org/abs/2006.08572) | NeurIPS |                              -                               |
| 2018 | [DATASET DISTILLATION](https://arxiv.org/abs/1811.10959)     |    -    |     [code](https://github.com/SsnL/dataset-distillation)     |



